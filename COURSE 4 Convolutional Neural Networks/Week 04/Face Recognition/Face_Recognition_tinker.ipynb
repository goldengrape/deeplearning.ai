{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 持续训练\n",
    "\n",
    "问题提出: 如果人脸识别在使用中发现准确率并不够高, 是否可以继续改进? 如何在已有的基础之上继续改进? \n",
    "\n",
    "解决方法: 建立并联的判别神经网络, 将A人脸的128位编码和待测人脸的128位编码作为输入, 二值判别输出 \n",
    "* 路径A: 计算二阶范数距离, 并以原题目中的阈值作为分界, 形成输出\n",
    "* 路径B: 待训练神经网络, 早期时参数值都很小, 因此输出值也很小, 但可被训练. \n",
    "\n",
    "路径A和路径B的加权平均作为最终输出. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:05:06.969529Z",
     "start_time": "2017-11-20T05:04:59.213142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Add\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform, RandomNormal\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:07:32.047874Z",
     "start_time": "2017-11-20T05:05:06.971543Z"
    }
   },
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:07:34.227021Z",
     "start_time": "2017-11-20T05:07:32.050374Z"
    }
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代数计算路径\n",
    "\n",
    "距离使用norm 2范数进行计算. 输出根据阈值进行sigmoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:07:34.450471Z",
     "start_time": "2017-11-20T05:07:34.228882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_face=img_to_encoding(\"images/camera_0.jpg\", FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:22:56.113589Z",
     "start_time": "2017-11-20T05:22:55.871395Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_path(x1,x2,threshold):\n",
    "    d = tf.norm((x1-x2),axis=-1)\n",
    "    # output=1-Activation('sigmoid')(d-threshold)\n",
    "    output = 0.5 - (tf.sign(d-threshold))/2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:22:56.787436Z",
     "start_time": "2017-11-20T05:22:56.569985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659393\n",
      "out = [array([ 1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_face=img_to_encoding(\"images/camera_0.jpg\", FRmodel)\n",
    "target_face= database[\"younes\"]\n",
    "d0=np.linalg.norm((test_face-target_face),axis=-1,keepdims=False)[0]\n",
    "print(d0)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    faceA_codes = tf.placeholder(\"float\", [1,128])\n",
    "    faceB_codes = tf.placeholder(\"float\", [1,128])\n",
    "    A = dist_path(faceA_codes,faceB_codes,0.7)\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A], \n",
    "                   feed_dict={\n",
    "                       faceA_codes: test_face, \n",
    "                       faceB_codes: target_face, \n",
    "                       K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正路径\n",
    "建立一个神经网络引入修正值, 后期可以通过调整修正路径中的参数对结果进行微调. 对于使用范围比较局限的场景, 例如公司员工的人脸识别, 需要泛化的要求较低, 即使修正路径发生了过拟合也可以接受. \n",
    "\n",
    "为了初期不影响代数路径的结果, 修正路径的参数初始化可以使用均值为0的小量, 使得初始输出结果很小. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:32:53.669849Z",
     "start_time": "2017-11-20T05:32:53.481361Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tinker_path(x1,x2): \n",
    "    X=tf.concat([x1,x2],axis=-1)\n",
    "#     X = Flatten()(X)\n",
    "    X = Dense(128, activation='relu', \n",
    "              kernel_initializer = RandomNormal(mean=0.0, stddev=0.05, seed=None))(X)\n",
    "    X = Dense(128, activation='relu', \n",
    "              kernel_initializer = RandomNormal(mean=0.0, stddev=0.05, seed=None))(X)\n",
    "    X = Dense(1, activation='tanh', \n",
    "              kernel_initializer = RandomNormal(mean=0.0, stddev=0.05, seed=None))(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:33:40.081578Z",
     "start_time": "2017-11-20T05:33:39.734117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659393\n",
      "out = [array([[ 0.0001808]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_face=img_to_encoding(\"images/camera_0.jpg\", FRmodel)\n",
    "target_face= database[\"younes\"]\n",
    "d0=np.linalg.norm((test_face-target_face),axis=-1,keepdims=False)[0]\n",
    "print(d0)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    faceA_codes = tf.placeholder(\"float\", [1,128])\n",
    "    faceB_codes = tf.placeholder(\"float\", [1,128])\n",
    "    A = tinker_path(faceA_codes,faceB_codes)\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A], \n",
    "                   feed_dict={\n",
    "                       faceA_codes: test_face, \n",
    "                       faceB_codes: target_face, \n",
    "                       K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并路径\n",
    "代数计算路径和神经网络路径的结果进行加权平均, 获得最终的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:34:38.609454Z",
     "start_time": "2017-11-20T05:34:38.563519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def face_tinker(x1,x2,threshold,alpha):\n",
    "    paths=[dist_path(x1,x2,threshold), tinker_path(x1,x2)]\n",
    "    X=Add()([ a*path for (a,path) in zip(alpha,paths)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:34:40.111894Z",
     "start_time": "2017-11-20T05:34:39.707961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659393\n",
      "out = [array([[ 0.70005423]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_face=img_to_encoding(\"images/camera_0.jpg\", FRmodel)\n",
    "target_face= database[\"younes\"]\n",
    "d0=np.linalg.norm((test_face-target_face),axis=-1,keepdims=False)[0]\n",
    "print(d0)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    faceA_codes = tf.placeholder(\"float\", [1,128])\n",
    "    faceB_codes = tf.placeholder(\"float\", [1,128])\n",
    "    threshold = 0.7\n",
    "    alpha=[0.7,0.3]\n",
    "    A = face_tinker(faceA_codes,faceB_codes,threshold,alpha)\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A], \n",
    "                   feed_dict={\n",
    "                       faceA_codes: test_face, \n",
    "#                        faceB_codes: database[\"felix\"], \n",
    "                       faceB_codes: target_face, \n",
    "                       K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正路径的训练\n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "114px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
